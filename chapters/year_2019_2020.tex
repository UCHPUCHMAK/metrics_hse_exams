% !TEX root = ../metrics_hse_exams.tex

\subsection{ИП, вспомнить всё!}

\begin{enumerate}

    \item Сфорулируйте теорему о трёх перпендикулярах и обратную к ней. Нарисуйте картинку.
  
    \item Для матрицы
  $
    A=\begin{pmatrix}
    7 & 5  \\
    5 & 7  \\
    \end{pmatrix}
  $
  
    \begin{enumerate}
    \item Найдите собственные числа и собственные векторы матрицы;
    \item Найдите определитель $\det A$ и след $\tr A$;
   \item Известно, что $B = 2019A^{-1} + 2018I$, где $I$ — единичная матрица.
   Найдите собственные числа $B$, определитель $\det B$ и след $\tr B$.
  
    \end{enumerate}
  
  
    \item Блондинка Маша встретила 200 динозавров.
    Средний рост динозавров оказался равен 20 метров, а выборочное стандартное отклонение — 5 метров.
  
    \begin{enumerate}
      \item Постройте 95\% доверительный интервал для математического ожидания роста динозавра.
      \item На уровне значимости 1\% проверьте гипотезу о том, что математическое ожидание
      роста равно 22 метрам. Против альтернативной гипотезе о неравенстве.
      \item Укажите $P$-значение для теста в предыдущем пункте.
    \end{enumerate}
  
   \item В убийстве равновероятно виноват либо Джон, либо Билл. 
   На месте убийства найдена кровь убийцы, совпадающая с группой крови Джона. Такой группой крови обладает 10\% населения. Группа крови Билла неизвестна. 
   Какова услованя вероятность того, что Билл — убийца?
  
  \end{enumerate}
  

\subsection{Контрольная работа №1, базовая часть, 19.10.2019}

время написания: 1 час 20 минут

\subsubsection*{Тест}

% \setcounter{question}{0}

\begin{question}
Случайные величины $X$ и $Y$ независимы и имеют нормальное распределение с $\E(X) = 0$, $\Var(X)=1$, $\E(Y)=5$, $\Var(Y) = 4$. 
Величина $Z = 2X + Y$ имеет распределение
\begin{answerlist}
  \item $\cN(5;5)$
  \item $\cN(5;8)$
  \item $\chi^2_2$
  \item $t_2$
  \item $F_{1,1}$
  \item нет верного ответа
\end{answerlist}
\end{question}


\begin{question}
Оценка $T_n = T(X_1, X_2, \ldots, X_n)$ называется несмещённой оценкой параметра $\theta$, если
\begin{answerlist}[2]
  \item $\E(T_n) = T_n$
  \item $T_n = 0$
  \item $\lim_{n\to\infty} \P(|T_n - \theta|>\e) = 0$ при $\e>0$
  \item $\E(T_n) = 0$
  \item $\E(T_n) = \theta$
  \item нет верного ответа
\end{answerlist}
\end{question}



\begin{question}
Оценена регрессия $\hat Y = 300 + 6W$, где $R^2 = 0.85$ и $W_i = X_i / X_{i-1}$.

Если объясняющая переменная будет выражена в процентах, $\tilde W_i = 100(X_i - X_{i-1})/X_{i-1}$, то результаты оценки регрессии примут вид
\begin{answerlist}
  \item $\hat Y_i = 3 + 6 \tilde W_i$, $R^2= 0.85$
  \item $\hat Y_i = 300 + 600 \tilde W_i$, $R^2= 0.85$
  \item $\hat Y_i = 306 + 0.06 \tilde W_i$, $R^2= 0.85$
  \item $\hat Y_i = 300 + 6 \tilde W_i$, $R^2= 0.085$
  \item $\hat Y_i = 300 + 6 \tilde W_i$, $R^2= 0.85$
  \item нет верного ответа
\end{answerlist}
\end{question}


\begin{question}
Оценка ковариационной матрицы оценок коэффициентов регрессии $Y=X\beta + \e$ пропорциональна
\begin{answerlist}
  \item $(XX^T)^{-1}$
  \item $X^TX$
  \item $(X^TX)^{-1}$
  \item $XX^T$
  \item $X^TY$
  \item нет верного ответа
\end{answerlist}
\end{question}

\begin{question}
Среди предпосылок теоремы Гаусса-Маркова фигурирует условие
\begin{answerlist}
  \item $\E(Y_i)=0$
  \item $\e_i \sim \cN(0;\sigma^2)$
  \item $\E(\e_i)=1$
  \item $\Var(\e_i)=const$
  \item $\Var(\e_i)=1$
  \item нет верного ответа
\end{answerlist}
\end{question}


\begin{question}
Оценено уравнение парной регрессии $Y_i = \beta_0 + \beta_1 X_i + \e_i$, причём МНК-оценка
коэффициента $\beta_1$ равна 5, а стандартная ошибка оценки равна $0.25$.

Значение $t$-статистики для проверки гипотезы, что этот коэффициент равен 4, есть
\begin{answerlist}
  \item $-2$
  \item $4$
  \item $-4$
  \item $2$
  \item $20$
  \item нет верного ответа
\end{answerlist}
\end{question}

\begin{question}
P-значение при проверке некоторой гипотезы $H_0$ оказалось равно $0.002$.

Гипотеза $H_0$ не отвергается при уровне значимости
\begin{answerlist}
    \item 10\%
    \item 0.1\%  
    \item 1\%
  \item 5\%
  \item всех перечисленных
  \item нет верного ответа
\end{answerlist}
\end{question}


\begin{question}
Известно, что выборочный коэффициент корреляции между $X$ и $Y$ равен $0.25$. 
В регрессии $Y$ на константу и $X$ коэффициент $R^2$ равен
\begin{answerlist}
  \item $25$
  \item $0.25$
  \item $0.5$
  \item $0.0625$
  \item $\sqrt{0.5}$
  \item нет верного ответа
\end{answerlist}
\end{question}



\begin{question}
Исследователь оценил регрессию $\hat Y_i = 90 + 3 X_i$. Если увеличить переменную $X$ на 10\%,
а $Y$ — на 10 единиц, то 

\begin{answerlist}[2]
  \item оценка коэффициента $\beta_0$ уменьшится, а $\beta_1$ — увеличится
  \item оценка коэффициента $\beta_0$ увеличится, а $\beta_1$ — уменьшится
  \item оценки коэффициентов $\beta_0$, $\beta_1$ не изменятся
  \item оценки коэффициентов $\beta_0$, $\beta_1$ уменьшатся
  \item оценки коэффициентов $\beta_0$, $\beta_1$ увеличатся
  \item нет верного ответа
\end{answerlist}
\end{question}

\begin{question}
Исследователь оценил регрессию $\hat Y_i = \underset{(0.1)}{30} + \underset{(0.5)}{6} X_i$, причём $\sum_i (X_i - \bar X)^2=4$. Все предпосылки теоремы Гаусса-Маркова выполнены. 

В скобках приведены стандартные ошибки коэффициентов. 
Несмещённая оценка дисперсии ошибок регрессии равна 
\begin{answerlist}
  \item $0.25$
  \item $2$
  \item $1$
  \item $0.125$
  \item $2\sqrt{0.5}$
  \item нет верного ответа
\end{answerlist}
\end{question}


\subsubsection*{Задачи}

\begin{enumerate}
\item Найдите величины Q1, \ldots, Q10, пропущенные в таблицах: 

\begin{tabular}{lr} \toprule
Indicator & Value \\
\midrule
Multiple R          & Q1 \\
$R^2$     			& Q2 \\
Adjusted $R^2$     	& 0.54 \\
Standart error 		& Q3 \\
Observations		& 800 \\
\bottomrule
\end{tabular}\hspace{2cm}
\begin{tabular}{lrrrrr} \toprule
ANOVA     	 &  df 	& SS		& MS 	& F & Significance F \\
\midrule
Regression   & Q4   	& 42.9  	& 42.9	&  923 	& 	0	\\
Residual     & 798  	& 37.0  	& 46	&  	&     	\\
Total        & 799  	& Q5        &    	&  	&     	\\
\bottomrule
\end{tabular}


\begin{tabular}{rrrrrrr}
\toprule
 			& Coef. 	& St. error	& t-stat & P-value	& Lower 95\% 	& Upper 95\% \\
\midrule
Intercept 	& -25.24 	& 2.0 	& Q6 		& 0 	&  Q7		& -21.31 \\
totspan		& 1.7		& Q8    & 30.4 	    & 0 	&  Q9	    & Q10 \\
\bottomrule
\end{tabular}


\item Грета Тунберг оценила зависимость средней температуры на Земном шаре в градусах, $Y_i$, 
от количества своих постов в твиттере в соответствующий день, $X_i$, по 52 дням:

\[
\hat Y_i = \underset{(1.24)}{-1.53} + \underset{(0.12)}{0.14} X_i, \text{ где } \sum_i (X_i - \bar X)^2 =52.4 \text{ и } \bar X = 10
\]

\begin{enumerate}
\item (2 балла) Проверьте гипотезы о незначимости каждого коэффициента при уровне значимости $\alpha = 0.01$.
\item (2 балла) Проверьте гипотезу о равенстве углового коэффициента 2 при альтернативной гипотезе, что 
коэффициент больше 2 и уровне значимости $\alpha = 0.01$.
\item (1 балл) Найдите оценку дисперсии $\e_i$ в модели $Y_i = \beta_0 + \beta_1 X_i + \e_i$.
\item (3 балла) Постройте 95\%-ый доверительный интервал для индивидуального прогноза $Y$, если $X=10$.
    
    
\end{enumerate}
    
\item Рассмотрим парную регрессию $\hat Y_i = \hat\beta_0 + \hat\beta_1 X_i$.
    
\begin{enumerate}
\item (1 балл) Дайте определение коэффициента детерминации $R^2$.
\item (1 + 2 балла) В каких пределах может лежать $R^2$ в указанной парной регрессии? Докажите сформулированное утверждение.
\item (1 + 2 балла) Как связан коэффициент $R^2$ и выборочная корреляция зависимой переменной и регрессора? Докажите сформулированное утверждение. 
\end{enumerate}
    
    
% Примечание: при доказательстве можно использовать условия первого порядка, важно их аккуратно сформулировать. 



\end{enumerate}


\subsection{Контрольная работа №1, базовая часть — решения}

Тест: BECCD BBDBC

\begin{enumerate}
\item $Q1 = 0.73$, $Q2 = 0.537$, $Q3 = 0.215$, $Q4 = 1$, $Q5 = 799$, 
$Q6 = -12.62$, $Q7 = -29.16$, $Q8 = 0.056$, $Q9 = 1.59$, $Q10 = 1.81$


\item 
\begin{enumerate}
\item $t_{crit} = 2.58$, $t_{\hb_0} = -1.23$, $t_{\hb_1} = 1.17$, оба коэффициента не значимы.
\item $t_{crit} = 2.4$, $t_{obs} = -15.5$, гипотеза $H_0$ отвергается.
\item $\hat \sigma^2 = 0.12^2 \cdot 52.4 = 0.755$
\item $\hat Y = -1.53 + 1.4 = -0.13$, $[-0.13 - 2\cdot \sqrt{0.77}; -0.13 + 2\cdot \sqrt{0.77} ]$
\end{enumerate}

\item $R^2 \in [0;1]$, коэффициент $R^2$ равен квадрату выборочной корреляции между вектором $X$ и вектором $Y$.
\[
\frac{ESS}{TSS} = \left(\frac{\sum (Y_i - \bar Y)(X_i - \bar X)}{\sqrt{\sum (Y_i - \bar Y)^2 \sum (X_i - \bar X)^2}}\right)^2
\]
  
\end{enumerate}


\subsection{Контрольная работа №1, ИП часть, 19.10.2019}

время написания: 2 час 20 минут


Ровно 207 лет назад, 19 октября 1812 года, Наполеон покинул Москву! :)

\begin{enumerate}

\item Известно, что $A$ — постоянная симметричная матрица, $r$ — вектор и $f(r) = r^T Ar / r^Tr$.

\begin{enumerate}
\item Найдите $df$. 
\item Перепешите условие $df=0$ в виде $Ar = const \cdot r$. Докажите, что в любом экстремуме функции $f$ вектор $r$ будет собственным вектором матрицы $A$. 
\end{enumerate}


\item Рассмотрим модель $y = X\beta + u$ с неслучайными регрессорами $X$, $\E(u)=0$ и $\Var(u) = \sigma^2 I$.

\begin{enumerate}
\item Найдите $\Var(\hat y)$, $\Var(y - \hat y)$, $\E(y - \hat y)$. Укажите размеры каждой найденной матрицы. 
\end{enumerate}

Есть дополнительная тестовая выборка, $y^{new}$, $X^{new}$, и для неё $y^{new} = X^{new}\beta + u^{new}$ с $\E(u^{new})=0$ и $\Var(u^{new}) = \sigma^2 I$
В тестовой выборке $n^{new}$ наблюдений. Ошибки двух выборок некоррелированы, $\Cov(u, u^{new}) = 0$.
Прогнозы для тестовой выборки мы строим, используя старые оценки $\hat\beta$, то есть $\hat y^{new} = X^{new}\hat\beta$.

\begin{enumerate}[resume]
\item Найдите $\Var(\hat y^{new})$, $\Var(y^{new} - \hat y^{new})$, $\E(y^{new} - \hat y^{new})$. Укажите размеры каждой найденной матрицы. 
\end{enumerate}
    

\item В выборке всего 5 наблюдений. Исследователь Бонапарт оценивает парную регрессию $\hat y_i = \hat \beta_1 + \hat \beta_2 x_i$.
Однако, истинная модель имеет вид $y_i = 1 + 2 z_i + u_i$. 
Известно, что $u \sim \cN(0;\sigma^2 \cdot I)$, $x^T = (1, 2, 3, 4, 5)$.

\begin{enumerate}
\item Найдите $\E(\hb)$, $\Var(\hb)$, $\E(RSS)$, если $z^T = (2, 3, 4, 5, 6)$.
\item Найдите $\E(\hb)$, $\Var(\hb)$, $\E(RSS)$, если $z^T = (5, 4, 3, 2, 1)$.
\end{enumerate}

\item Грета Тунберг, Илон Маск и Джеки Чан выбрали ортогональный базис в $5$-мерном пространстве, 
$v_1$, $v_2$, $v_3$, $v_4$, $v_5$. Вектор $v_1$ — это вектор из единичек. 

Грета Тунберг построила регрессию $y$ на $v_1$, $v_2$ и $v_3$.
Илон Маск построил регрессию того же вектора $y$ на $v_1$, $v_4$, $v_5$.
Джеки Чан построил регрессию того же вектора $y$ на все элементы базиса.

\begin{enumerate}

\item Изобразите в $5$-мерном пространстве остатки и прогнозы всех трёх регрессий. 

\item Как связаны между собой $RSS$, $ESS$ и $TSS$ всех трёх регрессий?

\item Как связаны между собой оценки коэффициентов всех трёх регрессий?

\end{enumerate}

\item Рассмотрим модель $y_i = \beta_1 + \beta_2 x_i + u_i$ с неслучайным регрессором.

\begin{enumerate}
\item Максимально аккуратно сформулируйте теорему Гаусса-Маркова. С «если» и «то». 
С формальным пояснением к любому используемому статистическому термину. 
\end{enumerate}

Дополнительно известно, что $\beta_2 = 0$.
\begin{enumerate}[resume]
\item Найдите $\E(R^2)$.
\item Найдите $\E(R^2_{adj})$.
% \item Обобщите найденные ожидания на случай множественной регрессии с константой. 
\end{enumerate}

\end{enumerate}



\subsection{Контрольная работа №1, ИП часть — решения}

