\documentclass[12pt]{article}

\usepackage{tikz} % картинки в tikz
\usepackage{microtype} % свешивание пунктуации

\usepackage{array} % для столбцов фиксированной ширины

\usepackage{indentfirst} % отступ в первом параграфе

\usepackage{sectsty} % для центрирования названий частей
\allsectionsfont{\centering}

\usepackage{amsmath, amsthm, amssymb} % куча стандартных математических плюшек

\usepackage{comment}

\usepackage[top=2cm, left=1.2cm, right=1.2cm, bottom=2cm]{geometry} % размер текста на странице

\usepackage{lastpage} % чтобы узнать номер последней страницы

\usepackage{enumitem} % дополнительные плюшки для списков
%  например \begin{enumerate}[resume] позволяет продолжить нумерацию в новом списке
\usepackage{caption}


\usepackage{fancyhdr} % весёлые колонтитулы
\pagestyle{fancy}
\lhead{Эконометрика}
\chead{}
\rhead{2019-10-19, контрольная 1, ИП-часть}
\lfoot{}
\cfoot{}
\rfoot{\thepage/\pageref{LastPage}}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}



\usepackage{todonotes} % для вставки в документ заметок о том, что осталось сделать
% \todo{Здесь надо коэффициенты исправить}
% \missingfigure{Здесь будет Последний день Помпеи}
% \listoftodos - печатает все поставленные \todo'шки


% более красивые таблицы
\usepackage{booktabs}
% заповеди из докупентации:
% 1. Не используйте вертикальные линни
% 2. Не используйте двойные линии
% 3. Единицы измерения - в шапку таблицы
% 4. Не сокращайте .1 вместо 0.1
% 5. Повторяющееся значение повторяйте, а не говорите "то же"



\usepackage{fontspec}
\usepackage{polyglossia}

\setmainlanguage{russian}
\setotherlanguages{english}

% download "Linux Libertine" fonts:
% http://www.linuxlibertine.org/index.php?id=91&L=1
\setmainfont{Linux Libertine O} % or Helvetica, Arial, Cambria
% why do we need \newfontfamily:
% http://tex.stackexchange.com/questions/91507/
\newfontfamily{\cyrillicfonttt}{Linux Libertine O}

\AddEnumerateCounter{\asbuk}{\russian@alph}{щ} % для списков с русскими буквами
\setlist[enumerate, 2]{label=\asbuk*),ref=\asbuk*}

%% эконометрические сокращения
\DeclareMathOperator{\Cov}{\mathbb{C}ov}
\DeclareMathOperator{\Corr}{\mathbb{C}orr}
\DeclareMathOperator{\Var}{\mathbb{V}ar}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\tr}{trace}
\def \hb{\hat{\beta}}
\def \hs{\hat{\sigma}}
\def \htheta{\hat{\theta}}
\def \s{\sigma}
\def \hy{\hat{y}}
\def \hY{\hat{Y}}
\def \v1{\vec{1}}
\def \e{\varepsilon}
\def \he{\hat{\e}}
\def \z{z}
\def \hVar{\widehat{\Var}}
\def \hCorr{\widehat{\Corr}}
\def \hCov{\widehat{\Cov}}
\def \cN{\mathcal{N}}


\begin{document}
 

Ровно 207 лет назад, 19 октября 1812 года, Наполеон покинул Москву! :)

\begin{enumerate}

\item Известно, что $A$ — постоянная симметричная матрица, $r$ — вектор и $f(r) = r^T Ar / r^Tr$.

\begin{enumerate}
\item Найдите $df$. 
\item Перепешите условие $df=0$ в виде $Ar = const \cdot r$. Докажите, что в любом экстремуме функции $f$ вектор $r$ будет собственным вектором матрицы $A$. 
\end{enumerate}


\item Рассмотрим модель $y = X\beta + u$ с неслучайными регрессорами $X$, $\E(u)=0$ и $\Var(u) = \sigma^2 I$.

\begin{enumerate}
\item Найдите $\Var(\hat y)$, $\Var(y - \hat y)$, $\E(y - \hat y)$. Укажите размеры каждой найденной матрицы. 
\end{enumerate}

Есть дополнительная тестовая выборка, $y^{new}$, $X^{new}$, и для неё $y^{new} = X^{new}\beta + u^{new}$ с $\E(u^{new})=0$ и $\Var(u^{new}) = \sigma^2 I$
В тестовой выборке $n^{new}$ наблюдений. Ошибки двух выборок некоррелированы, $\Cov(u, u^{new}) = 0$.
Прогнозы для тестовой выборки мы строим, используя старые оценки $\hat\beta$, то есть $\hat y^{new} = X^{new}\hat\beta$.

\begin{enumerate}[resume]
\item Найдите $\Var(\hat y^{new})$, $\Var(y^{new} - \hat y^{new})$, $\E(y^{new} - \hat y^{new})$. Укажите размеры каждой найденной матрицы. 
\end{enumerate}
    

\item В выборке всего 5 наблюдений. Исследователь Бонапарт оценивает парную регрессию $\hat y_i = \hat \beta_1 + \hat \beta_2 x_i$.
Однако, истинная модель имеет вид $y_i = 1 + 2 z_i + u_i$. 
Известно, что $u \sim \cN(0;\sigma^2 \cdot I)$, $x^T = (1, 2, 3, 4, 5)$.

\begin{enumerate}
\item Найдите $\E(\hb)$, $\Var(\hb)$, $\E(RSS)$, если $z^T = (2, 3, 4, 5, 6)$.
\item Найдите $\E(\hb)$, $\Var(\hb)$, $\E(RSS)$, если $z^T = (5, 4, 3, 2, 1)$.
\end{enumerate}

\item Грета Тунберг, Илон Маск и Джеки Чан выбрали ортогональный базис в $5$-мерном пространстве, 
$v_1$, $v_2$, $v_3$, $v_4$, $v_5$. Вектор $v_1$ — это вектор из единичек. 

Грета Тунберг построила регрессию $y$ на $v_1$, $v_2$ и $v_3$.
Илон Маск построил регрессию того же вектора $y$ на $v_1$, $v_4$, $v_5$.
Джеки Чан построил регрессию того же вектора $y$ на все элементы базиса.

\begin{enumerate}

\item Изобразите в $5$-мерном пространстве остатки и прогнозы всех трёх регрессий. 

\item Как связаны между собой $RSS$, $ESS$ и $TSS$ всех трёх регрессий?

\item Как связаны между собой оценки коэффициентов всех трёх регрессий?

\end{enumerate}

\item Рассмотрим модель $y_i = \beta_1 + \beta_2 x_i + u_i$ с неслучайным регрессором.

\begin{enumerate}
\item Максимально аккуратно сформулируйте теорему Гаусса-Маркова. С «если» и «то». 
С формальным пояснением к любому используемому статистическому термину. 
\end{enumerate}

Дополнительно известно, что $\beta_2 = 0$.
\begin{enumerate}[resume]
\item Найдите $\E(R^2)$.
\item Найдите $\E(R^2_{adj})$.
% \item Обобщите найденные ожидания на случай множественной регрессии с константой. 
\end{enumerate}

\end{enumerate}


\end{document}